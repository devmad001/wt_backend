{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "README \n",
    "NEED TO CHANGE THE PATHS TO THE CHECK IMAGES\n",
    "\n",
    "1:dir_to_process \n",
    "2: output_dir_for_extracted_data\n",
    "\n",
    "\n",
    "\n",
    "dir_to_process must be made and contain the jpg images of the checks to be processed\n",
    "\n",
    "output_dir_for_extracted_data will be created and contain the unstructured gpt4v data in a text file and the gpt4 extractor tool formated data in json format\n",
    "\n",
    "\n",
    "AND Update OpenAI key in the openai.api_key = os.environ['WATCH_TOWER_OPENAI_KEY'] line\n",
    "\n",
    "openai_api_key = os.environ['WATCH_TOWER_OPENAI_KEY']\n",
    "openai.api_key = os.environ['WATCH_TOWER_OPENAI_KEY']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import openai\n",
    "import os\n",
    "\n",
    "#Base path for the check image\n",
    "#TEST ONE: NO MEMO FIELD\n",
    "dir_to_process = \"app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65caaffb9b6ff316a779f525/check_images_meta/\"\n",
    "output_dir_for_extracted_data = \"app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65caaffb9b6ff316a779f525/extracted_data/\"\n",
    "#TODO: once done apply to above\n",
    "#dir_to_process = \"app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65caaffb9b6ff316a779f525/small test/\"\n",
    "\n",
    "\n",
    "\n",
    "#TEST Two: WITH MEMO FIELD\n",
    "dir_to_process =\"app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/\"\n",
    "output_dir_for_extracted_data = \"app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/extracted_data/\"\n",
    "#Example of the fields in the check\n",
    "#TODO: UPDATE\n",
    "#check_visual_prompting_example_path = \"/app/FinAware/visual prompting of a check.jpg\"\n",
    "#base64_check_visual_prompting_example_image = encode_image(check_visual_prompting_example_path)\n",
    "\n",
    "#NOTE: In production turn this off.\n",
    "include_images_with_results = False\n",
    "\n",
    "#More space because saves images with the results but easier to debug and review the results. Can click on both results and image\n",
    "include_images_with_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altered version of finaware_check_dat_extract.ipynb\n",
    "#Supports dir input of jpg files\n",
    "\n",
    "#UPDATE THE PATHS TO YOUR OPENAI API KEY\n",
    "openai_api_key = os.environ['WATCH_TOWER_OPENAI_KEY']\n",
    "openai.api_key = os.environ['WATCH_TOWER_OPENAI_KEY']\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#Personal API key\n",
    "#openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "#Watch Tower API Key\n",
    "\n",
    "\n",
    "import base64\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a bank teller's tool to assist in manual data entry of checks. You are designed to extract and validate information from personal or business checks, including the check creation date, check maker's full name and address, check maker's phone number, check maker's bank information, payee information, signature line, check amount (numerical and written), check number, routing number, and account number.\n",
    "You are also responsible for performing necessary pre-processing steps on the input image to enhance the readability of the text, such as image normalization, denoising, and binarization. You must ensure that the extracted data is accurate and correctly formatted, correcting any OCR misreads or errors.\n",
    "Your goal is to provide the bank teller with structured information that can be easily verified and processed.\n",
    "\n",
    "Input: Accept an image of a personal or business check.\n",
    "Image Pre-processing: Perform necessary pre-processing steps on the input image to enhance the readability of the text. This may include image normalization, denoising, and binarization to prepare the image for OCR.\n",
    "OCR Execution: Apply OCR technology to the pre-processed image to extract textual content from the entire check image.\n",
    "\n",
    "Text Parsing and Extraction:\n",
    "Check Creation Date: Identify and extract the date the check is written on. Validate that this date is not in the future.\n",
    "Check Maker's Full Name and Address: Locate the top left corner of the check for the check maker's full name and address. Ensure the entire address is captured, including city, state, and zip code.\n",
    "Check Maker's Phone Number: If present, extract the phone number of the person or business who wrote the check, including the area code.\n",
    "Check Maker's Bank Information: Extract the bank name and address from the check, focusing on any visible details that indicate the financial institution.\n",
    "Payee Information: Identify the \"Pay to the order of\" field to extract the name of the person or business the check is written to.\n",
    "Signature Line: Locate and confirm the presence of a signature on the signature line.\n",
    "Check Amount (Numerical): Extract the numerical amount of the check, typically found on the right side.\n",
    "Check Amount (Words): Extract the check amount written in words, usually located on the line below the payee's name.\n",
    "Bottom Check Number: Identify and extract the check number from the MICR line at the bottom of the check.\n",
    "Top Right Check Number: Extract the check number located in the top right corner of the check.\n",
    "Routing Number: Extract the 9-digit ABA routing number from the MICR format on the bottom left of the check.\n",
    "Account Number: Identify and extract the 10-12 digit account number from the MICR line on the bottom left of the check.\n",
    "Data Validation and Correction:\n",
    "Perform validation checks on extracted data to ensure accuracy. This includes verifying the format of dates, phone numbers, routing numbers, and account numbers.\n",
    "Correct any OCR misreads or errors in the extracted text based on common patterns or validation rules.\n",
    "Output: Structure the extracted information according to the specified schema, making each piece of information available as a separate feature for further processing or verification by bank tellers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "model_version = \"gpt-4-vision-preview\" \n",
    "#model_version =\"gpt-4-1106-vision-preview\"\n",
    "model = ChatOpenAI(temperature=0, model = model_version )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\"\"\"\n",
    "Checks and balances \n",
    "\n",
    "Could be differences in values \n",
    "check_amount == check_word_amount\n",
    "\n",
    "TODO: bottom_check_number can have a leading 0 which is not seen in the top_right_check_number. \n",
    "TODO: Remove the leading 0 from bottom_check_number and compare with top_right_check_number \n",
    "Bottom could be written from the signature line.\n",
    "bottom_check_number == top_right_check_number\n",
    "\n",
    "Check maker is the person/business who wrote the check\n",
    "\"\"\"\n",
    "\n",
    "class BankTransaction(BaseModel):\n",
    "    \"\"\"A bank transaction statement entry.\"\"\"\n",
    "    posting_date: str = Field(description=\"The date the transaction was posted.\")\n",
    "    transaction_description: str = Field(description=\"Description of the transaction.\")\n",
    "    deposits_credits: Optional[float] = Field(description=\"Amount of deposits or credits in the transaction.Determines the amount of money that is being added to the account.Consider if numbers are negative or positive.\")\n",
    "    withdrawals_debits: Optional[float] = Field(description=\"Amount of withdrawals or debits in the transaction.Determines the amount of money that is being added to the account.Consider if numbers are negative or positive.\")\n",
    "    daily_balance: float = Field(description=\"The daily balance after the transaction.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Same name on signup form\n",
    "class bank_check(BaseModel):\n",
    "    \"\"\"A bank or personal check.\"\"\"\n",
    "    check_creation_date: str = Field(description=\"The date the check is written (cannot be a future date)\")\n",
    "    check_maker_full_name: str = Field(description=\"Full name of the Person/business who wrote the check usually in the top left corner on the check.\")\n",
    "    check_maker_address: str = Field(description=\"Address of the Person/business who wrote the check usually in the top left corner on the check. Capture the whole address including city, state, and zip code.\")\n",
    "    check_maker_phone_number: Optional[str] = Field(description=\"Phone number of the Person/business who wrote the check usually in the top left corner on the check. Capture the whole phone number including area code.\")\n",
    "    check_maker_bank_name: Optional[str] = Field(description=\"Bank name of the Person/business who wrote the check.\")\n",
    "    check_maker_bank_address: Optional[str] = Field(description=\"Bank address of the Person/business who wrote the check.\")\n",
    "    check_maker_bank_info: Optional[str] = Field(description=\"Any additional Bank information of the Person/business who wrote the check.\")\n",
    "    payee: str = Field(description=\"Person/business to whom the check is written. Usually next to the word 'Pay to the order of' on the check.\")\n",
    "    signature_line: str= Field(description=\"Signature line on the check. Describe anything remarkable about the signature line.\")\n",
    "    check_amount: str= Field(description=\"The amount of the check written in numbers, usually on the right side of the check\")\n",
    "    check_word_amount: str= Field(description=\"The amount of the check written in words, usually on the line below the payee's name\")\n",
    "    bottom_check_number: int= Field(description=\"Printed on the check and appears in the MICR line on the bottom of the check.\")\n",
    "    top_right_check_number: int= Field(description=\"Printed on the check and appears in the top right corner of the check.\")\n",
    "    routing_number : int= Field(description=\"ABA Routing Number (MICR Format). The first set of numbers on the bottom left of the check. It is a 9-digit number\")\n",
    "    account_number : int= Field(description=\"The second set of numbers in MICR Format on the bottom left of the check. It is a 10-12 digit number\")\n",
    "    check_memo_or_for : str = Field(description=\"Memo or For on the check. Can be used to describe the purpose of the check or any other relevant information.\")\n",
    "    ocr_errors: Optional[str] = Field(description=\"Describe any fields of the check that might be questionable or erroneous due to OCR or logical errors.\")\n",
    "\n",
    "    \n",
    "    \n",
    "class money_order(BaseModel):\n",
    "    \"\"\"A money order.\"\"\"\n",
    "    payee_name : Optional[str] = Field(description=\"The payee's name i.e. the person or company the money order is being made out to\")\n",
    "    payee_address: str = Field(description=\"The payee's address\")\n",
    "    money_order_memo : str = Field(description=\"The memo on the money order\")\n",
    "    purchaser_name : Optional[str] = Field(description=\"The purchaser's name on the money order\")\n",
    "    purchaser_address : Optional[str] = Field(description=\"The purchaser's address on the money order\")\n",
    "    amount: float = Field(description=\"The amount of the money order\")\n",
    "\n",
    "#payee_account_number: Optional[str] = Field(description=\"The payee's bank account number where the money order is being deposited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "extractor_model_non_vision = ChatOpenAI(temperature=0)\n",
    "\n",
    "extraction_functions = [convert_pydantic_to_openai_function(bank_check)]\n",
    "#CANT use tool usage on gpt4V currently as of 2-14-2024\n",
    "extraction_model = extractor_model_non_vision.bind(functions=extraction_functions, function_call={\"name\": \"bank_check\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This would be applied to the output from gpt4v model which will be raw and verbose, this model will summarize.\n",
    "prompt_wo_image = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", \"{input}\")\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt_wo_image | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#print(openai_api_key)\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {openai_api_key}\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_38_0_0.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_38_0_1.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_38_0_2.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_46_0_0.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_46_0_1.jpg\n",
      "Error: /app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_46_0_1.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_46_0_2.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_46_0_3.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_46_0_4.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_46_0_5.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_53_0_0.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_53_0_1.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_53_0_2.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_65_0_0.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_73_0_0.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_73_0_1.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_73_0_2.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_73_0_3.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_81_0_0.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_81_0_1.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_81_0_3.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_81_0_4.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_81_0_5.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_81_0_6.jpg\n",
      "/app/FinAware/CHECK_MEDIA_STORAGE/CHECK_MEDIA_STORAGE/65a8168eb3ac164610ea5bc2/check_images_meta/NEW AGE VENDING LLC_check_81_0_7.jpg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "# Get a list of all jpg files in the directory\n",
    "jpg_files = glob.glob(f\"{dir_to_process}/*.jpg\")\n",
    "\n",
    "#print(jpg_files)\n",
    "\n",
    "\n",
    "for jpg_file in jpg_files:\n",
    "    # Get the full path to the image\n",
    "    full_path = os.path.abspath(jpg_file)\n",
    "    print(full_path)\n",
    "    \n",
    "    image_name = os.path.basename(full_path)\n",
    "    path_without_file = os.path.dirname(full_path)\n",
    "    image_name_without_extension = os.path.splitext(image_name)[0]\n",
    "    \n",
    "    #Analytics file to see if the file was processed\n",
    "    file_path = os.path.join(output_dir_for_extracted_data, f\"{image_name_without_extension}_unstructured.txt\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Check if the output directory exists\n",
    "    if not os.path.exists(output_dir_for_extracted_data):\n",
    "      # If not, create the directory\n",
    "      os.makedirs(output_dir_for_extracted_data)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "      \n",
    "      if include_images_with_results:\n",
    "        #Move images into folder with results for easier viewing. \n",
    "        # Construct the destination path\n",
    "        copy_of_check_destination_path = os.path.join(output_dir_for_extracted_data, image_name)\n",
    "\n",
    "        # Copy the image\n",
    "        #shutil.copy(full_path, output_dir_for_extracted_data)\n",
    "        shutil.copy(full_path, copy_of_check_destination_path)\n",
    "    \n",
    "    \n",
    "      # Pass the full path to the encode_image function\n",
    "      base64_check_image=encode_image(full_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      \"\"\"\n",
    "      CAN'T use tool usage in gpt4v so going to use this method to get the output\n",
    "      \"\"\"\n",
    "\n",
    "      text_input_prompt_second = \"Please help me in data entry of this check.\"\n",
    "\n",
    "\n",
    "      payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": [\n",
    "          {\"role\": \"system\", \"content\": system_message},\n",
    "          \n",
    "            {\"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": text_input_prompt_second\n",
    "              },\n",
    "              {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                  \"url\": f\"data:image/jpeg;base64,{base64_check_image}\",\"detail\": \"high\"\n",
    "                }\n",
    "              }]\n",
    "          }\n",
    "            \n",
    "              \n",
    "          ], \"max_tokens\": 1000\n",
    "          }\n",
    "      \n",
    "      \n",
    "      response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "      \n",
    "      try:\n",
    "        unpacked=response.json()\n",
    "      except Exception as e:\n",
    "        print(f\"Error: {full_path}\")\n",
    "        with open(f'{output_dir_for_extracted_data}/unpack_error.txt', 'a') as f:\n",
    "          f.write(f\"Error:{e} {full_path}\\n\")\n",
    "    \n",
    "      unstructured_content=unpacked['choices'][0]['message']['content']\n",
    "      #print(unstructured_content)\n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      #Saving the first pass of the gpt4v model without tools. Text is unstructured. Output from this model is used as input into another model\n",
    "      with open(f\"{output_dir_for_extracted_data}/{image_name_without_extension}_unstructured.txt\", 'w') as f:\n",
    "          f.write(unstructured_content)\n",
    "\n",
    "      \n",
    "      try:\n",
    "        response_formatted = extraction_chain.invoke({\"input\":unstructured_content})\n",
    "        \n",
    "      except json.JSONDecodeError as e:\n",
    "          print(f\"JSONDecodeError: {e}{full_path}\")\n",
    "          with open(f'{output_dir_for_extracted_data}/errored_files.txt', 'a') as f:\n",
    "            f.write(f\"JSONDecodeError: {e} {full_path}\\n\")\n",
    "            \n",
    "      except Exception as e:\n",
    "          print(f\"Error: {full_path}\")\n",
    "          with open(f'{output_dir_for_extracted_data}/errored_files.txt', 'a') as f:\n",
    "            f.write(f\"Error:{e} {full_path}\\n\")\n",
    "      \n",
    "      \n",
    "      json_data = json.dumps(response_formatted)\n",
    "      #Saving the second pass of the gpt4 model with structured output tools. Text is structured to meet the bank_check model\n",
    "      #with open(f\"{path_without_file}/{image_name_without_extension}_extracted.json\", 'w') as f:\n",
    "      with open(f\"{output_dir_for_extracted_data}/{image_name_without_extension}_extracted.json\", 'w') as f:\n",
    "          f.write(json_data)\n",
    "    \n",
    "    \n",
    "    else: \n",
    "        print(f\"File exists not computing again: {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " except OutputParserException as e:\n",
    "          print(f\"OutputParserException: {e}{full_path}\")\n",
    "          with open('{output_dir_for_extracted_data}/errored_files.txt', 'a') as f:\n",
    "            f.write(f\"OutputParserException: {e} {full_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "output from gpt4v without tool usage need to transform into json, so will need one more extractor LLM ( that's not vision) \n",
    "to transform into json because gpt4V can't use tools\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
